import os
import numpy as np
from paddleocr import PaddleOCR
from PIL import Image, ImageOps
import json
import re
import Levenshtein
from kor_ocr import save_all_ocr_results_to_txt

# PaddleOCR ì´ˆê¸°í™”
ocr = PaddleOCR(lang='korean', use_angle_cls=True, use_gpu=True)

# ë°ì´í„° ê²½ë¡œ ì„¤ì •
IMAGE_PATH = r"E:\OCR\image"
GROUND_TRUTH_PATH = r"E:\OCR\correct"
OUTPUT_OCR_TXT_PATH = r"C:\Users\osh\visualTranslation\OCR\KOR_OCR\all_ocr_result.txt"
OUTPUT_CORRECT_TXT_PATH = r"C:\Users\osh\visualTranslation\OCR\KOR_OCR\all_correct_results.txt"

# OCR ì •ë‹µì—ì„œ "xxx" ì œê±°
def clean_ground_truth(text):
    return ' '.join([word for word in text.split() if word != "xxx"]).strip()

# ì •ë‹µ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ ë¡œë“œ (ëª¨ë“  annotationì˜ í…ìŠ¤íŠ¸ë¥¼ ê²°í•©)
def load_ground_truth_combined(json_path):
    try:
        with open(json_path, 'r', encoding='utf-8') as file:
            data = json.load(file)
            annotations = data.get("annotations", [])
            # "xxx"ì¸ í•­ëª©ì€ ì œì™¸í•˜ê³  ë‚˜ë¨¸ì§€ í…ìŠ¤íŠ¸ë“¤ì„ ê²°í•©í•©ë‹ˆë‹¤.
            texts = [ann.get("text", "") for ann in annotations if ann.get("text", "").lower() != "xxx"]
            combined_text = ' '.join(texts).strip()
            return clean_ground_truth(combined_text)
    except Exception:
        return None

# ì´ë¯¸ì§€ì—ì„œ ê°€ì¥ í° ë¬¸ì ì˜ì—­ ì¶”ì¶œ (ROI ì„ íƒ)
def extract_largest_text_region(image_path):
    try:
        with Image.open(image_path) as img:
            img = img.convert("L")            # í‘ë°± ë³€í™˜
            img = ImageOps.invert(img)         # ìƒ‰ìƒ ë°˜ì „ (í…ìŠ¤íŠ¸ ê°•ì¡°)
            img_array = np.array(img)
            # ì´ì§„í™”
            threshold = 128
            binary_img = np.where(img_array > threshold, 255, 0).astype(np.uint8)
            # ìœ¤ê³½ì„  ê²€ì¶œ
            non_zero_coords = np.column_stack(np.where(binary_img > 0))
            if non_zero_coords.shape[0] == 0:
                return img  # ì›ë³¸ ì´ë¯¸ì§€ ë°˜í™˜
            # ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°
            x_min, y_min = non_zero_coords.min(axis=0)
            x_max, y_max = non_zero_coords.max(axis=0)
            # ROI ì¶”ì¶œ (ë¬¸ì ì˜ì—­ë§Œ ìë¥´ê¸°)
            return img.crop((y_min, x_min, y_max, y_max))
    except Exception:
        return None

# ì •í™•ë„ í‰ê°€ í•¨ìˆ˜ë“¤
def token_based_accuracy(pred_text, gt_text):
    pred_tokens = set(pred_text.split())
    gt_tokens = set(gt_text.split())
    correct = len(pred_tokens & gt_tokens)
    total = len(gt_tokens)
    return correct, total

def substring_matching_accuracy(pred_text, gt_text):
    correct = sum(1 for token in gt_text.split() if token in pred_text)
    total = len(gt_text.split())
    return correct, total

def edit_distance_accuracy(pred_text, gt_text):
    distance = Levenshtein.distance(pred_text, gt_text)
    max_len = max(len(pred_text), len(gt_text))
    return max_len - distance, max_len

# í‰ê°€ ì‹¤í–‰ (OCR ê²°ê³¼ ì¶”ì¶œ ë° ì €ì¥)
def evaluate_paddle_ocr(image_path, ground_truth_path):
    SUPPORTED_EXTENSIONS = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.gif')
    all_results = {}  # OCR ê²°ê³¼ ì €ì¥ ë”•ì…”ë„ˆë¦¬

    total_images = 0   # ì „ì²´ ì´ë¯¸ì§€ ê°œìˆ˜
    ocr_images = 0     # OCR ê²°ê³¼ê°€ ë‚˜ì˜¨ ì´ë¯¸ì§€ ê°œìˆ˜

    # ì •í™•ë„ ëˆ„ì  ë³€ìˆ˜
    total_token_correct = 0
    total_token_total = 0
    total_substring_correct = 0
    total_substring_total = 0
    total_edit_correct = 0
    total_edit_total = 0
    total_highest = 0  # ê° ì´ë¯¸ì§€ì˜ ìµœê³  ì •í™•ë„ ëˆ„ì 

    if not os.path.exists(image_path) or len(os.listdir(image_path)) == 0:
        print("âŒ ì²˜ë¦¬í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return all_results

    for file in os.listdir(image_path):
        if file.lower().endswith(SUPPORTED_EXTENSIONS):
            total_images += 1
            try:
                image_file_path = os.path.join(image_path, file)
                json_file_path = os.path.join(ground_truth_path, os.path.splitext(file)[0] + '.json')

                # OCR ì •ë‹µ(ground truth)ì€ í‰ê°€ ì‹œ combined í˜•íƒœë¡œ ì‚¬ìš©
                if os.path.exists(json_file_path):
                    ground_truth = load_ground_truth_combined(json_file_path)
                    if ground_truth is None:
                        continue
                else:
                    continue

                cropped_image = extract_largest_text_region(image_file_path)
                if cropped_image is None:
                    continue

                result = ocr.ocr(np.array(cropped_image), cls=True)
                if not result or not result[0]:
                    error_message = "OCR ê²°ê³¼ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. (ì¸ì‹ ì‹¤íŒ¨ ë˜ëŠ” ì´ë¯¸ì§€ í’ˆì§ˆ ë¬¸ì œ)"
                    print(f"ğŸ“Œ íŒŒì¼: {file}")
                    print(f"âŒ [ì¶œë ¥ ì˜¤ë¥˜ ë° ì›ì¸] : {error_message}\n")
                    continue

                ocr_images += 1
                paddle_text = ' '.join([line[1][0] for line in result[0]]).strip()

                print(f"ğŸ“Œ íŒŒì¼: {file}")
                print(f"ğŸ” OCR ê²°ê³¼: {paddle_text}")
                print(f"âœ… OCR ì •ë‹µ: {ground_truth}")

                token_correct, token_total = token_based_accuracy(paddle_text, ground_truth)
                substring_correct, substring_total = substring_matching_accuracy(paddle_text, ground_truth)
                edit_correct, edit_total = edit_distance_accuracy(paddle_text, ground_truth)

                token_accuracy = (token_correct / token_total * 100) if token_total > 0 else 0
                substring_accuracy = (substring_correct / substring_total * 100) if substring_total > 0 else 0
                edit_accuracy = (edit_correct / edit_total * 100) if edit_total > 0 else 0

                highest_accuracy = max(token_accuracy, substring_accuracy, edit_accuracy)
                if highest_accuracy == token_accuracy:
                    highest_metric = "í† í° ë‹¨ìœ„"
                elif highest_accuracy == substring_accuracy:
                    highest_metric = "ë¶€ë¶„ ë¬¸ìì—´"
                else:
                    highest_metric = "í¸ì§‘ ê±°ë¦¬ ê¸°ë°˜"
                total_highest += highest_accuracy

                print(f" : í† í° ë‹¨ìœ„ ì •í™•ë„: {token_accuracy:.2f}%")
                print(f" : ë¶€ë¶„ ë¬¸ìì—´ ì •í™•ë„: {substring_accuracy:.2f}%")
                print(f" : í¸ì§‘ ê±°ë¦¬ ê¸°ë°˜ ì •í™•ë„: {edit_accuracy:.2f}%")
                print(f"[ê°€ì¥ ë†’ì€ ì •í™•ë„ ê¸°ì¤€ : '{highest_metric}' - {highest_accuracy:.2f}%]\n")

                total_token_correct += token_correct
                total_token_total += token_total
                total_substring_correct += substring_correct
                total_substring_total += substring_total
                total_edit_correct += edit_correct
                total_edit_total += edit_total

                # OCR ê²°ê³¼ ì €ì¥
                for idx, detection in enumerate(result[0]):
                    try:
                        bbox_points = detection[0]
                        xs = [point[0] for point in bbox_points]
                        ys = [point[1] for point in bbox_points]
                        flat_bbox = [min(xs), min(ys), max(xs), max(ys)]
                        text = detection[1][0]
                        key = f"{os.path.splitext(file)[0]}_{idx}"
                        all_results[key] = {"txt": text, "bbox": flat_bbox}
                    except Exception as e:
                        print(f"ê²€ì¶œ í•­ëª© ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ì¸ë±ìŠ¤ {idx}): {e}")
                        continue

            except Exception as e:
                print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
                continue

    overall_token_accuracy = (total_token_correct / total_token_total * 100) if total_token_total > 0 else 0
    overall_substring_accuracy = (total_substring_correct / total_substring_total * 100) if total_substring_total > 0 else 0
    overall_edit_accuracy = (total_edit_correct / total_edit_total * 100) if total_edit_total > 0 else 0
    overall_highest_average = (total_highest / ocr_images) if ocr_images > 0 else 0

    print("========================================================")
    print(f"[ì „ì²´ ì´ë¯¸ì§€ ê°œìˆ˜: {total_images}ê°œ / OCR ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ê°œìˆ˜: {ocr_images}ê°œ]")
    print(f" : í† í° ë‹¨ìœ„ í‰ê·  ì •í™•ë„: {overall_token_accuracy:.2f}%")
    print(f" : ë¶€ë¶„ ë¬¸ìì—´ í‰ê·  ì •í™•ë„: {overall_substring_accuracy:.2f}%")
    print(f" : í¸ì§‘ ê±°ë¦¬ ê¸°ë°˜ í‰ê·  ì •í™•ë„: {overall_edit_accuracy:.2f}%")
    print(f"[ìµœê³  ì •í™•ë„ í‰ê· : {overall_highest_average:.2f}%]")
    print("========================================================")

    return all_results

# ì •ë‹µì„ ì €ì¥í•˜ëŠ” í•¨ìˆ˜ (ê° ì´ë¯¸ì§€ì— ëŒ€í•´ ëª¨ë“  annotationì˜ í…ìŠ¤íŠ¸ë¥¼ ê²°í•©)
def save_all_correct_results_to_txt(ground_truth_path, output_file):
    correct_results = {}
    for file in os.listdir(ground_truth_path):
        if file.lower().endswith('.json'):
            filepath = os.path.join(ground_truth_path, file)
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    annotations = data.get("annotations", [])
                    # "xxx" í•­ëª©ì€ ì œê±°í•˜ê³  ë‚˜ë¨¸ì§€ í…ìŠ¤íŠ¸ë¥¼ ê²°í•©
                    texts = [ann.get("text", "") for ann in annotations if ann.get("text", "").lower() != "xxx"]
                    combined_text = ' '.join(texts).strip()
                    key = os.path.splitext(file)[0]
                    correct_results[key] = {"txt": combined_text}
            except Exception as e:
                print(f"íŒŒì¼ {file} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(correct_results, f, ensure_ascii=False, indent=4)
    print(f"ì •ë‹µ íŒŒì¼ì´ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    results = evaluate_paddle_ocr(IMAGE_PATH, GROUND_TRUTH_PATH)
    if results:
        save_all_ocr_results_to_txt(results, OUTPUT_OCR_TXT_PATH)
        save_all_correct_results_to_txt(GROUND_TRUTH_PATH, OUTPUT_CORRECT_TXT_PATH)